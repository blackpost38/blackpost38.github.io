---
title: Locust 사용 후기
date: 2019-03-23 16:58:05
tags: python, django, load test, stress test
---

목적
---
최근 **Locust**를 이용해서 stress test를 한 후기를 남긴다.

Locust 사용한 이유
---
- 시스템을 인수인계 받는 도중에 테스트에 대한 니즈가 생김
  - API가 제대로 작동을 하는가?
  - 어느 정도 부하를 견딜 수 있으며, 과도한 부하 상태에서 시스템은 어떤 행동을 하는가?
- 어느 정도 부하를 견디는지 확인하기 위해 스트레스 테스트 툴을 검색하기 시작
- JMeter, Grinder 등 많이 쓰이는 툴이 있었지만, Locust를 선택
  - python으로 테스트 코드를 작성할 수 있다.
  - 사용법이 간단하여, 금방 익힐 수 있다.

Locust 사용 팁
---
- 사용법은 단순하며, 문서보면 누구나 다 따라할 수 있는 수준
  - Locust를 고른 이유이기도 함
  - 때문에 사용법을 정리하기 보다는 팁을 남기는 것이 낫다고 판단
- 다른 툴에 비해 낮은 RPS
  - 하나의 머신에서 수천명의 사용자의 행동을 시뮬레이션할 수 있도록 만들어진 툴
  - 또한, python 코드로 사용자의 행동 시나리오를 만드는 것이 가능
  - 따라서 단순 RPS 수치 측정 용도 보다는 위의 두 특징을 고려해서 Locust를 사용할 것인지 판단하는 것이 좋을듯
  - 물론 적당한 RPS가 나오므로 큰 문제는 없다고 생각
    - AWS 상에서 `t2.micro`를 사용했을때, 약 500 rps 정도가 나옴
- 멀티 코어 & Docker를 사용해 Master&Slave를 구축하면 성능을 최대한 끌어올릴 수 있다.
  - `docker-compose` 용 locust는 [sernst/locusts](https://github.com/sernst/locusts)을 사용했다.
    - 간단한 방법으로 Master와 Slave를 지정할 수 있다.
  - 그러나 극적인 효과는 없다 => `t2.micro`로 약 600 ~ 700 rps 정도가 나오는 수준
  - AWS를 사용하는 환경이라면, 여러 인스턴스로 Locust를 연결하면 퍼포먼스가 많이 오른다.
    - `t2.micro` 인스턴스를 15개 정도 연결 시켜서 7000 rps까지 찍어봤다.
  - 성능이 좋은 인스턴스를 여러 개 연결하더라도, 하나의 Locust만 실행하면 성능이 그렇게 좋아지진 않는다.
    - 4 core 짜리를 여러개 돌려봤는데 rps가 그렇게 좋아지지 않더라
    - 알고보니 CPU를 하나만 소모하기 때문에 극적으로 퍼포먼스를 끌어올릴 수 없었던 것
    - Docker를 여러개 실행하여 CPU를 최대한 활용하는 것이 대안이 될 것
- 그런데 500 rps 정도면 왠만한 서비스의 부하 테스트는 가능하다는 생각
  - 실제로 테스트 대상이었던 시스템은 최대 100rps를 찍는 수준
- 앞서 언급한 것보다 중요한건 시나리오 테스트 기능
  - 테스트 대상 시스템은 복잡한 기능이 없어 시나리오를 코드로 작성해서 테스트 해보진 않음
  - Locust의 강점은 코드로 어느 정도 사용자의 행동을 테스트할 수 있다는 것
    - 페이지 이동, 어떤 데이터 호출 등